{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Y3LjFT5tqS-W",
        "outputId": "2ae6269b-b128-40d0-b887-3b59f9959585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48647, 55)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
              "0                                6279  ...          0.0          0.0   \n",
              "1                                6225  ...          0.0          0.0   \n",
              "2                                6121  ...          0.0          0.0   \n",
              "3                                6211  ...          0.0          0.0   \n",
              "4                                6172  ...          0.0          0.0   \n",
              "\n",
              "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
              "0          0.0          0.0          0.0          0.0          0.0   \n",
              "1          0.0          0.0          0.0          0.0          0.0   \n",
              "2          0.0          0.0          0.0          0.0          0.0   \n",
              "3          0.0          0.0          0.0          0.0          0.0   \n",
              "4          0.0          0.0          0.0          0.0          0.0   \n",
              "\n",
              "   Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0          0.0          0.0         5.0  \n",
              "1          0.0          0.0         5.0  \n",
              "2          0.0          0.0         2.0  \n",
              "3          0.0          0.0         2.0  \n",
              "4          0.0          0.0         5.0  \n",
              "\n",
              "[5 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98c5eb36-fdee-4f31-a396-b5ffee8a507a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98c5eb36-fdee-4f31-a396-b5ffee8a507a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98c5eb36-fdee-4f31-a396-b5ffee8a507a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98c5eb36-fdee-4f31-a396-b5ffee8a507a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-817d974f-5da5-465a-924d-8bec668a95d8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-817d974f-5da5-465a-924d-8bec668a95d8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-817d974f-5da5-465a-924d-8bec668a95d8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"covtype.csv\")   # or your file name\n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------ LOAD DATA ------------\n",
        "df = pd.read_csv(\"covtype.csv\")   # change filename if needed\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "# ------------ CHECK FOR NAN IN TARGET ------------\n",
        "print(\"NaN in target:\", df[\"Cover_Type\"].isna().sum())\n",
        "\n",
        "# ------------ DROP ROWS WHERE TARGET IS NaN ------------\n",
        "df = df.dropna(subset=[\"Cover_Type\"])\n",
        "print(\"Shape after dropping NaN rows:\", df.shape)\n",
        "\n",
        "# ------------ SEPARATE FEATURES AND LABEL ------------\n",
        "X = df.drop(\"Cover_Type\", axis=1)\n",
        "y = df[\"Cover_Type\"]\n",
        "\n",
        "# ------------ TRAIN / TEST SPLIT ------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TkK08AakPUw",
        "outputId": "8d6fcc91-647e-40f8-cb48-077308ab03e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (48647, 55)\n",
            "NaN in target: 1\n",
            "Shape after dropping NaN rows: (48646, 55)\n",
            "Train shape: (38916, 54) (38916,)\n",
            "Test shape: (9730, 54) (9730,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data and transform both train and test\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Scaling completed!\")\n",
        "print(\"Train scaled shape:\", X_train_scaled.shape)\n",
        "print(\"Test scaled shape:\", X_test_scaled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCogQEvbk0Nt",
        "outputId": "91c3f8c3-e806-466a-afc4-68b55d30a9ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaling completed!\n",
            "Train scaled shape: (38916, 54)\n",
            "Test scaled shape: (9730, 54)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Create logistic regression model\n",
        "logreg = LogisticRegression(\n",
        "    max_iter=2000,   # Increase iterations for convergence\n",
        "    n_jobs=-1        # Use all CPU cores\n",
        ")\n",
        "\n",
        "# Train model\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "pred_lr = logreg.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, pred_lr))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred_lr))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSg33u9ik6a2",
        "outputId": "197cb0fc-b2f6-4b7b-b1e6-ad64643bc870"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8039054470709147\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.51      0.62      1963\n",
            "         2.0       0.83      0.95      0.88      5556\n",
            "         3.0       0.63      0.57      0.60       432\n",
            "         4.0       0.80      0.87      0.83       432\n",
            "         5.0       0.73      0.60      0.66       483\n",
            "         6.0       0.63      0.65      0.64       432\n",
            "         7.0       0.90      0.85      0.87       432\n",
            "\n",
            "    accuracy                           0.80      9730\n",
            "   macro avg       0.76      0.71      0.73      9730\n",
            "weighted avg       0.80      0.80      0.79      9730\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1008  899    0    0   16    0   40]\n",
            " [ 216 5256    8    0   55   18    3]\n",
            " [   0    3  245   55   20  109    0]\n",
            " [   0    0   38  375    0   19    0]\n",
            " [   9  156    9    0  289   20    0]\n",
            " [   0   10   87   41   13  281    0]\n",
            " [  63    0    0    0    1    0  368]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Create SVM model (RBF kernel)\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    gamma='scale'\n",
        ")\n",
        "\n",
        "# Train SVM\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred_svm))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred_svm))\n"
      ],
      "metadata": {
        "id": "8cw4JsSwlNnK",
        "outputId": "20901fec-d7a8-4bea-c93b-5d6785461869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8343268242548818\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.81      0.61      0.70      1963\n",
            "         2.0       0.86      0.95      0.90      5556\n",
            "         3.0       0.67      0.66      0.66       432\n",
            "         4.0       0.80      0.93      0.86       432\n",
            "         5.0       0.83      0.66      0.74       483\n",
            "         6.0       0.66      0.65      0.65       432\n",
            "         7.0       0.93      0.83      0.87       432\n",
            "\n",
            "    accuracy                           0.83      9730\n",
            "   macro avg       0.79      0.75      0.77      9730\n",
            "weighted avg       0.83      0.83      0.83      9730\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1196  729    0    0   11    4   23]\n",
            " [ 192 5281   10    0   41   26    6]\n",
            " [   0    0  284   60    8   80    0]\n",
            " [   0    0   11  400    0   21    0]\n",
            " [  15  115   21    0  320   12    0]\n",
            " [   0   11   96   41    5  279    0]\n",
            " [  69    4    1    0    0    0  358]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5 — Neural Network (MLPClassifier)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "# Configure the MLP\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(256, 128),   # two layers: 256 -> 128\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    learning_rate_init=0.001,\n",
        "    batch_size=1024,                 # larger batch for speed on big data\n",
        "    max_iter=200,                    # cap iterations\n",
        "    early_stopping=True,             # stop if validation score not improving\n",
        "    n_iter_no_change=10,             # patience for early stopping\n",
        "    validation_fraction=0.1,         # 10% of train used as internal val set\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train and time it\n",
        "t0 = time.time()\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "t1 = time.time()\n",
        "\n",
        "print(f\"Training time: {(t1-t0):.1f} seconds\")\n",
        "\n",
        "# Predict & evaluate\n",
        "pred_nn = mlp.predict(X_test_scaled)\n",
        "print(\"Neural Network Accuracy:\", accuracy_score(y_test, pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred_nn))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred_nn))\n",
        "\n",
        "# If you want probabilities (for e.g. log-loss or calibration):\n",
        "# proba_nn = mlp.predict_proba(X_test_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oju1i5DpnXIg",
        "outputId": "bd3d05b8-776c-4e6f-9908-d1d2bf844522"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.94216737\n",
            "Validation score: 0.772097\n",
            "Iteration 2, loss = 0.54898407\n",
            "Validation score: 0.799332\n",
            "Iteration 3, loss = 0.49463360\n",
            "Validation score: 0.803700\n",
            "Iteration 4, loss = 0.46072408\n",
            "Validation score: 0.811922\n",
            "Iteration 5, loss = 0.43774358\n",
            "Validation score: 0.825797\n",
            "Iteration 6, loss = 0.41969748\n",
            "Validation score: 0.827852\n",
            "Iteration 7, loss = 0.40828829\n",
            "Validation score: 0.836588\n",
            "Iteration 8, loss = 0.39528335\n",
            "Validation score: 0.839414\n",
            "Iteration 9, loss = 0.38327156\n",
            "Validation score: 0.842754\n",
            "Iteration 10, loss = 0.37500949\n",
            "Validation score: 0.845324\n",
            "Iteration 11, loss = 0.36528408\n",
            "Validation score: 0.848921\n",
            "Iteration 12, loss = 0.35993972\n",
            "Validation score: 0.849435\n",
            "Iteration 13, loss = 0.35091083\n",
            "Validation score: 0.845581\n",
            "Iteration 14, loss = 0.34691804\n",
            "Validation score: 0.853803\n",
            "Iteration 15, loss = 0.34072823\n",
            "Validation score: 0.857143\n",
            "Iteration 16, loss = 0.33491233\n",
            "Validation score: 0.858171\n",
            "Iteration 17, loss = 0.32962783\n",
            "Validation score: 0.857914\n",
            "Iteration 18, loss = 0.32367967\n",
            "Validation score: 0.858171\n",
            "Iteration 19, loss = 0.31829536\n",
            "Validation score: 0.859969\n",
            "Iteration 20, loss = 0.31711835\n",
            "Validation score: 0.864080\n",
            "Iteration 21, loss = 0.30942361\n",
            "Validation score: 0.858684\n",
            "Iteration 22, loss = 0.30761435\n",
            "Validation score: 0.861768\n",
            "Iteration 23, loss = 0.30253161\n",
            "Validation score: 0.868448\n",
            "Iteration 24, loss = 0.29829496\n",
            "Validation score: 0.866650\n",
            "Iteration 25, loss = 0.29922458\n",
            "Validation score: 0.863309\n",
            "Iteration 26, loss = 0.29127862\n",
            "Validation score: 0.866136\n",
            "Iteration 27, loss = 0.28611823\n",
            "Validation score: 0.864337\n",
            "Iteration 28, loss = 0.28725861\n",
            "Validation score: 0.869733\n",
            "Iteration 29, loss = 0.28248695\n",
            "Validation score: 0.868962\n",
            "Iteration 30, loss = 0.27787649\n",
            "Validation score: 0.869219\n",
            "Iteration 31, loss = 0.27252183\n",
            "Validation score: 0.876413\n",
            "Iteration 32, loss = 0.26993683\n",
            "Validation score: 0.867934\n",
            "Iteration 33, loss = 0.26723094\n",
            "Validation score: 0.872045\n",
            "Iteration 34, loss = 0.26827130\n",
            "Validation score: 0.878726\n",
            "Iteration 35, loss = 0.26035599\n",
            "Validation score: 0.875385\n",
            "Iteration 36, loss = 0.25718278\n",
            "Validation score: 0.884378\n",
            "Iteration 37, loss = 0.25455981\n",
            "Validation score: 0.876670\n",
            "Iteration 38, loss = 0.25179011\n",
            "Validation score: 0.876156\n",
            "Iteration 39, loss = 0.25262787\n",
            "Validation score: 0.877955\n",
            "Iteration 40, loss = 0.24838829\n",
            "Validation score: 0.879496\n",
            "Iteration 41, loss = 0.24680093\n",
            "Validation score: 0.876670\n",
            "Iteration 42, loss = 0.24585233\n",
            "Validation score: 0.883350\n",
            "Iteration 43, loss = 0.23740125\n",
            "Validation score: 0.882837\n",
            "Iteration 44, loss = 0.23970385\n",
            "Validation score: 0.885406\n",
            "Iteration 45, loss = 0.23458141\n",
            "Validation score: 0.881809\n",
            "Iteration 46, loss = 0.23299131\n",
            "Validation score: 0.887718\n",
            "Iteration 47, loss = 0.23377850\n",
            "Validation score: 0.885149\n",
            "Iteration 48, loss = 0.22912099\n",
            "Validation score: 0.887205\n",
            "Iteration 49, loss = 0.22917886\n",
            "Validation score: 0.884635\n",
            "Iteration 50, loss = 0.23121297\n",
            "Validation score: 0.890545\n",
            "Iteration 51, loss = 0.22340818\n",
            "Validation score: 0.882580\n",
            "Iteration 52, loss = 0.21911144\n",
            "Validation score: 0.885406\n",
            "Iteration 53, loss = 0.21752655\n",
            "Validation score: 0.894913\n",
            "Iteration 54, loss = 0.21788235\n",
            "Validation score: 0.892857\n",
            "Iteration 55, loss = 0.21316980\n",
            "Validation score: 0.888232\n",
            "Iteration 56, loss = 0.21423543\n",
            "Validation score: 0.890288\n",
            "Iteration 57, loss = 0.21285733\n",
            "Validation score: 0.892600\n",
            "Iteration 58, loss = 0.21233035\n",
            "Validation score: 0.890288\n",
            "Iteration 59, loss = 0.20955263\n",
            "Validation score: 0.888746\n",
            "Iteration 60, loss = 0.20668859\n",
            "Validation score: 0.887461\n",
            "Iteration 61, loss = 0.20836454\n",
            "Validation score: 0.892343\n",
            "Iteration 62, loss = 0.20264802\n",
            "Validation score: 0.894656\n",
            "Iteration 63, loss = 0.20426276\n",
            "Validation score: 0.888232\n",
            "Iteration 64, loss = 0.20344884\n",
            "Validation score: 0.894913\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Training time: 78.3 seconds\n",
            "Neural Network Accuracy: 0.8986639260020555\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.87      0.82      0.85      1963\n",
            "         2.0       0.94      0.95      0.94      5556\n",
            "         3.0       0.73      0.69      0.71       432\n",
            "         4.0       0.88      0.94      0.91       432\n",
            "         5.0       0.86      0.88      0.87       483\n",
            "         6.0       0.74      0.77      0.76       432\n",
            "         7.0       0.91      0.94      0.93       432\n",
            "\n",
            "    accuracy                           0.90      9730\n",
            "   macro avg       0.85      0.86      0.85      9730\n",
            "weighted avg       0.90      0.90      0.90      9730\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1614  307    0    0    8    0   34]\n",
            " [ 216 5263    9    0   46   18    4]\n",
            " [   0    3  297   33   12   87    0]\n",
            " [   0    0   23  405    0    4    0]\n",
            " [   4   37    8    0  426    8    0]\n",
            " [   1    2   71   24    1  333    0]\n",
            " [  21    5    0    0    0    0  406]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRID SEARCH FOR ALL THREE MODELS\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "results = []\n",
        "\n",
        "# ---------- 1) Logistic Regression ----------\n",
        "print(\"----- GRID SEARCH: Logistic Regression -----\")\n",
        "lr = LogisticRegression(multi_class='multinomial', max_iter=5000, random_state=42)\n",
        "\n",
        "lr_param_grid = {\n",
        "    \"C\": [0.01, 0.1, 1.0, 10.0],\n",
        "    # solver 'saga' supports l1 too; using l2 here for stability\n",
        "    \"penalty\": [\"l2\"],\n",
        "    # use lbfgs or saga; lbfgs is usually faster for multinomial but supports only l2\n",
        "    \"solver\": [\"lbfgs\"]\n",
        "}\n",
        "\n",
        "gs_lr = GridSearchCV(\n",
        "    lr,\n",
        "    lr_param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "gs_lr.fit(X_train_scaled, y_train)\n",
        "t1 = time.time()\n",
        "print(f\"LR grid search time: {t1-t0:.1f}s\")\n",
        "\n",
        "best_lr = gs_lr.best_estimator_\n",
        "print(\"Best LR params:\", gs_lr.best_params_)\n",
        "print(\"Best LR CV accuracy:\", gs_lr.best_score_)\n",
        "\n",
        "pred_lr = best_lr.predict(X_test_scaled)\n",
        "acc_lr = accuracy_score(y_test, pred_lr)\n",
        "print(\"Test accuracy (LR):\", acc_lr)\n",
        "print(classification_report(y_test, pred_lr))\n",
        "\n",
        "results.append({\n",
        "    \"model\": \"LogisticRegression\",\n",
        "    \"best_params\": gs_lr.best_params_,\n",
        "    \"cv_best_score\": gs_lr.best_score_,\n",
        "    \"test_accuracy\": acc_lr\n",
        "})\n",
        "\n",
        "# ---------- 2) SVM (RBF) ----------\n",
        "print(\"\\n----- GRID SEARCH: SVM (RBF) -----\")\n",
        "svm = SVC(kernel='rbf', probability=False, random_state=42)\n",
        "\n",
        "svm_param_grid = {\n",
        "    \"C\": [0.1, 1.0, 10.0],\n",
        "    \"gamma\": [\"scale\", 0.01, 0.001]\n",
        "}\n",
        "\n",
        "gs_svm = GridSearchCV(\n",
        "    svm,\n",
        "    svm_param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "gs_svm.fit(X_train_scaled, y_train)\n",
        "t1 = time.time()\n",
        "print(f\"SVM grid search time: {t1-t0:.1f}s\")\n",
        "\n",
        "best_svm = gs_svm.best_estimator_\n",
        "print(\"Best SVM params:\", gs_svm.best_params_)\n",
        "print(\"Best SVM CV accuracy:\", gs_svm.best_score_)\n",
        "\n",
        "pred_svm = best_svm.predict(X_test_scaled)\n",
        "acc_svm = accuracy_score(y_test, pred_svm)\n",
        "print(\"Test accuracy (SVM):\", acc_svm)\n",
        "print(classification_report(y_test, pred_svm))\n",
        "\n",
        "results.append({\n",
        "    \"model\": \"SVM(RBF)\",\n",
        "    \"best_params\": gs_svm.best_params_,\n",
        "    \"cv_best_score\": gs_svm.best_score_,\n",
        "    \"test_accuracy\": acc_svm\n",
        "})\n",
        "\n",
        "# ---------- 3) Neural Network (MLP) ----------\n",
        "print(\"\\n----- GRID SEARCH: MLPClassifier -----\")\n",
        "mlp = MLPClassifier(max_iter=300, early_stopping=True, random_state=42)\n",
        "\n",
        "mlp_param_grid = {\n",
        "    \"hidden_layer_sizes\": [(128,), (256,), (256,128)],\n",
        "    \"alpha\": [1e-4, 1e-3],\n",
        "    \"learning_rate_init\": [1e-3, 5e-4]\n",
        "}\n",
        "\n",
        "gs_mlp = GridSearchCV(\n",
        "    mlp,\n",
        "    mlp_param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "gs_mlp.fit(X_train_scaled, y_train)\n",
        "t1 = time.time()\n",
        "print(f\"MLP grid search time: {t1-t0:.1f}s\")\n",
        "\n",
        "best_mlp = gs_mlp.best_estimator_\n",
        "print(\"Best MLP params:\", gs_mlp.best_params_)\n",
        "print(\"Best MLP CV accuracy:\", gs_mlp.best_score_)\n",
        "\n",
        "pred_mlp = best_mlp.predict(X_test_scaled)\n",
        "acc_mlp = accuracy_score(y_test, pred_mlp)\n",
        "print(\"Test accuracy (MLP):\", acc_mlp)\n",
        "print(classification_report(y_test, pred_mlp))\n",
        "\n",
        "results.append({\n",
        "    \"model\": \"MLP\",\n",
        "    \"best_params\": gs_mlp.best_params_,\n",
        "    \"cv_best_score\": gs_mlp.best_score_,\n",
        "    \"test_accuracy\": acc_mlp\n",
        "})\n",
        "\n",
        "# ---------- SUMMARY ----------\n",
        "summary_df = pd.DataFrame(results)\n",
        "print(\"\\n\\n=== SUMMARY ===\")\n",
        "print(summary_df[['model', 'cv_best_score', 'test_accuracy', 'best_params']])\n",
        "\n",
        "# Optionally show confusion matrices for each tuned model\n",
        "print(\"\\nConfusion matrix: Logistic Regression\")\n",
        "print(confusion_matrix(y_test, pred_lr))\n",
        "print(\"\\nConfusion matrix: SVM\")\n",
        "print(confusion_matrix(y_test, pred_svm))\n",
        "print(\"\\nConfusion matrix: MLP\")\n",
        "print(confusion_matrix(y_test, pred_mlp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyZkqo0Inv13",
        "outputId": "03e34597-6885-4326-bfa4-1899a83f8a77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- GRID SEARCH: Logistic Regression -----\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR grid search time: 43.3s\n",
            "Best LR params: {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Best LR CV accuracy: 0.802934525644979\n",
            "Test accuracy (LR): 0.8045220966084276\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.51      0.62      1963\n",
            "         2.0       0.83      0.95      0.88      5556\n",
            "         3.0       0.63      0.56      0.60       432\n",
            "         4.0       0.79      0.87      0.83       432\n",
            "         5.0       0.74      0.61      0.67       483\n",
            "         6.0       0.64      0.66      0.65       432\n",
            "         7.0       0.89      0.85      0.87       432\n",
            "\n",
            "    accuracy                           0.80      9730\n",
            "   macro avg       0.76      0.72      0.73      9730\n",
            "weighted avg       0.80      0.80      0.79      9730\n",
            "\n",
            "\n",
            "----- GRID SEARCH: SVM (RBF) -----\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "SVM grid search time: 1303.9s\n",
            "Best SVM params: {'C': 10.0, 'gamma': 'scale'}\n",
            "Best SVM CV accuracy: 0.8610340219960942\n",
            "Test accuracy (SVM): 0.863617677286742\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.84      0.69      0.76      1963\n",
            "         2.0       0.89      0.95      0.92      5556\n",
            "         3.0       0.72      0.64      0.68       432\n",
            "         4.0       0.84      0.95      0.89       432\n",
            "         5.0       0.86      0.75      0.80       483\n",
            "         6.0       0.71      0.76      0.74       432\n",
            "         7.0       0.93      0.92      0.93       432\n",
            "\n",
            "    accuracy                           0.86      9730\n",
            "   macro avg       0.83      0.81      0.82      9730\n",
            "weighted avg       0.86      0.86      0.86      9730\n",
            "\n",
            "\n",
            "----- GRID SEARCH: MLPClassifier -----\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP grid search time: 1039.3s\n",
            "Best MLP params: {'alpha': 0.0001, 'hidden_layer_sizes': (256, 128), 'learning_rate_init': 0.001}\n",
            "Best MLP CV accuracy: 0.9004522561414329\n",
            "Test accuracy (MLP): 0.915005138746146\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.89      0.84      0.87      1963\n",
            "         2.0       0.94      0.96      0.95      5556\n",
            "         3.0       0.80      0.76      0.78       432\n",
            "         4.0       0.90      0.94      0.92       432\n",
            "         5.0       0.87      0.89      0.88       483\n",
            "         6.0       0.81      0.80      0.81       432\n",
            "         7.0       0.96      0.90      0.93       432\n",
            "\n",
            "    accuracy                           0.92      9730\n",
            "   macro avg       0.88      0.87      0.88      9730\n",
            "weighted avg       0.91      0.92      0.91      9730\n",
            "\n",
            "\n",
            "\n",
            "=== SUMMARY ===\n",
            "                model  cv_best_score  test_accuracy  \\\n",
            "0  LogisticRegression       0.802935       0.804522   \n",
            "1            SVM(RBF)       0.861034       0.863618   \n",
            "2                 MLP       0.900452       0.915005   \n",
            "\n",
            "                                         best_params  \n",
            "0    {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}  \n",
            "1                      {'C': 10.0, 'gamma': 'scale'}  \n",
            "2  {'alpha': 0.0001, 'hidden_layer_sizes': (256, ...  \n",
            "\n",
            "Confusion matrix: Logistic Regression\n",
            "[[1006  900    0    0   15    1   41]\n",
            " [ 216 5257    8    0   55   17    3]\n",
            " [   0    3  243   56   21  109    0]\n",
            " [   0    0   39  376    0   17    0]\n",
            " [   9  158    8    0  294   14    0]\n",
            " [   0    8   85   42   13  284    0]\n",
            " [  63    0    0    0    1    0  368]]\n",
            "\n",
            "Confusion matrix: SVM\n",
            "[[1350  575    0    0   11    1   26]\n",
            " [ 210 5278    7    0   37   21    3]\n",
            " [   0    4  278   49    7   94    0]\n",
            " [   0    0   13  409    0   10    0]\n",
            " [   9   90   16    0  362    6    0]\n",
            " [   0    2   71   27    3  329    0]\n",
            " [  33    2    0    0    0    0  397]]\n",
            "\n",
            "Confusion matrix: MLP\n",
            "[[1650  289    0    0   11    0   13]\n",
            " [ 152 5349    9    0   38    6    2]\n",
            " [   0    6  329   24    7   66    0]\n",
            " [   0    0   18  408    0    6    0]\n",
            " [   1   44    4    0  432    2    0]\n",
            " [   0    7   51   19    8  347    0]\n",
            " [  42    2    0    0    0    0  388]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna tuning for LogisticRegression, SVM, and MLP (Neural Net)\n",
        "# Paste this cell and run. Requires optuna (install if necessary).\n",
        "\n",
        "# 0) Install optuna if not present\n",
        "try:\n",
        "    import optuna\n",
        "except Exception:\n",
        "    !pip install -q optuna\n",
        "    import optuna\n",
        "\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import time\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Use 3-fold stratified CV\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Common helper to evaluate an estimator\n",
        "def cv_score_estimator(estimator, X, y, cv):\n",
        "    scores = cross_val_score(estimator, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "# -------------------------\n",
        "# 1) Logistic Regression\n",
        "# -------------------------\n",
        "def objective_logreg(trial):\n",
        "    C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
        "    penalty = \"l2\"\n",
        "    solver = \"lbfgs\"\n",
        "\n",
        "    clf = LogisticRegression(\n",
        "        C=C,\n",
        "        penalty=penalty,\n",
        "        solver=solver,\n",
        "        multi_class=\"multinomial\",\n",
        "        max_iter=5000,\n",
        "        random_state=42\n",
        "    )\n",
        "    return cv_score_estimator(clf, X_train_scaled, y_train, cv)\n",
        "\n",
        "study_lr = optuna.create_study(direction=\"maximize\", study_name=\"LR_opt\")\n",
        "start = time.time()\n",
        "study_lr.optimize(objective_logreg, n_trials=30, n_jobs=1)\n",
        "end = time.time()\n",
        "print(f\"LogReg tuning done ({end-start:.1f}s). Best CV accuracy: {study_lr.best_value:.4f}\")\n",
        "print(\"Best LR params:\", study_lr.best_params)\n",
        "\n",
        "# Evaluate best LR on test set\n",
        "best_lr = LogisticRegression(\n",
        "    C=study_lr.best_params[\"C\"],\n",
        "    penalty=\"l2\",\n",
        "    solver=\"lbfgs\",\n",
        "    multi_class=\"multinomial\",\n",
        "    max_iter=5000,\n",
        "    random_state=42\n",
        ")\n",
        "best_lr.fit(X_train_scaled, y_train)\n",
        "pred_lr = best_lr.predict(X_test_scaled)\n",
        "test_acc_lr = accuracy_score(y_test, pred_lr)\n",
        "print(\"LR test accuracy:\", test_acc_lr)\n",
        "\n",
        "# -------------------------\n",
        "# 2) SVM (RBF)\n",
        "# -------------------------\n",
        "def objective_svm(trial):\n",
        "    C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
        "    gamma_option = trial.suggest_categorical(\"gamma_option\", [\"scale\", \"auto\", \"float\"])\n",
        "\n",
        "    if gamma_option == \"float\":\n",
        "        gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
        "    else:\n",
        "        gamma = gamma_option\n",
        "\n",
        "    clf = SVC(kernel=\"rbf\", C=C, gamma=gamma, probability=False, random_state=42)\n",
        "    return cv_score_estimator(clf, X_train_scaled, y_train, cv)\n",
        "\n",
        "study_svm = optuna.create_study(direction=\"maximize\", study_name=\"SVM_opt\")\n",
        "start = time.time()\n",
        "study_svm.optimize(objective_svm, n_trials=30, n_jobs=1)\n",
        "end = time.time()\n",
        "print(f\"SVM tuning done ({end-start:.1f}s). Best CV accuracy: {study_svm.best_value:.4f}\")\n",
        "print(\"Best SVM params:\", study_svm.best_params)\n",
        "\n",
        "# Extract gamma\n",
        "svm_params = study_svm.best_params\n",
        "if svm_params[\"gamma_option\"] == \"float\":\n",
        "    gamma_val = svm_params[\"gamma_float\"]\n",
        "else:\n",
        "    gamma_val = svm_params[\"gamma_option\"]\n",
        "\n",
        "# Evaluate best SVM\n",
        "best_svm = SVC(\n",
        "    kernel=\"rbf\",\n",
        "    C=svm_params[\"C\"],\n",
        "    gamma=gamma_val,\n",
        "    probability=False,\n",
        "    random_state=42\n",
        ")\n",
        "best_svm.fit(X_train_scaled, y_train)\n",
        "pred_svm = best_svm.predict(X_test_scaled)\n",
        "test_acc_svm = accuracy_score(y_test, pred_svm)\n",
        "print(\"SVM test accuracy:\", test_acc_svm)\n",
        "\n",
        "# -------------------------\n",
        "# 3) Neural Network (MLP)\n",
        "# -------------------------\n",
        "def objective_mlp(trial):\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    hidden = []\n",
        "    for i in range(n_layers):\n",
        "        hidden.append(trial.suggest_int(f\"n_units_l{i}\", 64, 512))\n",
        "    hidden_tuple = tuple(hidden)\n",
        "\n",
        "    alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
        "    lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512, 1024])\n",
        "\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=hidden_tuple,\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        alpha=alpha,\n",
        "        learning_rate_init=lr,\n",
        "        batch_size=batch_size,\n",
        "        max_iter=200,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=10,\n",
        "        validation_fraction=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "    return cv_score_estimator(clf, X_train_scaled, y_train, cv)\n",
        "\n",
        "study_mlp = optuna.create_study(direction=\"maximize\", study_name=\"MLP_opt\")\n",
        "start = time.time()\n",
        "study_mlp.optimize(objective_mlp, n_trials=30, n_jobs=1)\n",
        "end = time.time()\n",
        "print(f\"MLP tuning done ({end-start:.1f}s). Best CV accuracy: {study_mlp.best_value:.4f}\")\n",
        "print(\"Best MLP params:\", study_mlp.best_params)\n",
        "\n",
        "# Evaluate best MLP\n",
        "n_layers_best = study_mlp.best_params[\"n_layers\"]\n",
        "hidden_best = []\n",
        "for i in range(n_layers_best):\n",
        "    hidden_best.append(study_mlp.best_params[f\"n_units_l{i}\"])\n",
        "hidden_tuple_best = tuple(hidden_best)\n",
        "\n",
        "best_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=hidden_tuple_best,\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    alpha=study_mlp.best_params[\"alpha\"],\n",
        "    learning_rate_init=study_mlp.best_params[\"learning_rate_init\"],\n",
        "    batch_size=study_mlp.best_params[\"batch_size\"],\n",
        "    max_iter=400,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=10,\n",
        "    validation_fraction=0.1,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "best_mlp.fit(X_train_scaled, y_train)\n",
        "pred_mlp = best_mlp.predict(X_test_scaled)\n",
        "test_acc_mlp = accuracy_score(y_test, pred_mlp)\n",
        "print(\"MLP test accuracy:\", test_acc_mlp)\n",
        "\n",
        "# -------------------------\n",
        "# SUMMARY TABLE\n",
        "# -------------------------\n",
        "summary = pd.DataFrame([\n",
        "    {\"model\": \"LogisticRegression\", \"best_cv\": study_lr.best_value, \"test_acc\": test_acc_lr, \"best_params\": study_lr.best_params},\n",
        "    {\"model\": \"SVM(RBF)\", \"best_cv\": study_svm.best_value, \"test_acc\": test_acc_svm, \"best_params\": study_svm.best_params},\n",
        "    {\"model\": \"MLP\", \"best_cv\": study_mlp.best_value, \"test_acc\": test_acc_mlp, \"best_params\": study_mlp.best_params},\n",
        "])\n",
        "print(\"\\n=== Optuna summary ===\")\n",
        "print(summary)\n",
        "\n",
        "# Save studies\n",
        "joblib.dump(study_lr, \"optuna_study_lr.pkl\")\n",
        "joblib.dump(study_svm, \"optuna_study_svm.pkl\")\n",
        "joblib.dump(study_mlp, \"optuna_study_mlp.pkl\")\n",
        "print(\"Saved all Optuna studies.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40LCa_ZMuV_K",
        "outputId": "f68bffbe-82d8-4123-9dd7-355b6f0320af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 15:02:41,572] A new study created in memory with name: LR_opt\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:01,590] Trial 0 finished with value: 0.8026518655565834 and parameters: {'C': 4.516258552991755}. Best is trial 0 with value: 0.8026518655565834.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:14,890] Trial 1 finished with value: 0.801495528831329 and parameters: {'C': 0.287148824025192}. Best is trial 0 with value: 0.8026518655565834.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:21,442] Trial 2 finished with value: 0.801983759893103 and parameters: {'C': 0.6025423422389412}. Best is trial 0 with value: 0.8026518655565834.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:24,171] Trial 3 finished with value: 0.7957138452050571 and parameters: {'C': 0.01832551860095916}. Best is trial 0 with value: 0.8026518655565834.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:28,190] Trial 4 finished with value: 0.796433343611882 and parameters: {'C': 0.023329961904011674}. Best is trial 0 with value: 0.8026518655565834.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:34,656] Trial 5 finished with value: 0.8029088292733065 and parameters: {'C': 47.81345597461548}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:36,912] Trial 6 finished with value: 0.7941720629047179 and parameters: {'C': 0.008811591247084692}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:42,057] Trial 7 finished with value: 0.7996453900709221 and parameters: {'C': 0.0925333141844379}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:48,664] Trial 8 finished with value: 0.802703258299928 and parameters: {'C': 62.57380079552345}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:53,998] Trial 9 finished with value: 0.8018038852913968 and parameters: {'C': 0.3489459200500236}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:03:55,519] Trial 10 finished with value: 0.7785229725562749 and parameters: {'C': 0.0010639678172792415}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:01,888] Trial 11 finished with value: 0.8026775619282557 and parameters: {'C': 95.35897919173998}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:09,644] Trial 12 finished with value: 0.8024976873265496 and parameters: {'C': 64.89352955049435}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:16,018] Trial 13 finished with value: 0.8025747764415664 and parameters: {'C': 9.210382685728025}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:23,803] Trial 14 finished with value: 0.8026775619282557 and parameters: {'C': 16.112067416787575}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:30,125] Trial 15 finished with value: 0.8026518655565834 and parameters: {'C': 3.2945192490538453}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:37,978] Trial 16 finished with value: 0.8026261691849111 and parameters: {'C': 26.582595474104718}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:44,230] Trial 17 finished with value: 0.8023178127248433 and parameters: {'C': 1.597138532854583}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:51,968] Trial 18 finished with value: 0.8026775619282557 and parameters: {'C': 32.63040811379975}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:04:58,297] Trial 19 finished with value: 0.802703258299928 and parameters: {'C': 10.206081812299342}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:06,640] Trial 20 finished with value: 0.8025233836982218 and parameters: {'C': 1.275857091750212}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:13,402] Trial 21 finished with value: 0.802626169184911 and parameters: {'C': 10.556148514294774}. Best is trial 5 with value: 0.8029088292733065.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:21,269] Trial 22 finished with value: 0.8030116147599959 and parameters: {'C': 91.33127908521416}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:27,411] Trial 23 finished with value: 0.8025747764415665 and parameters: {'C': 55.83462814751254}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:35,020] Trial 24 finished with value: 0.8026775619282557 and parameters: {'C': 94.11234509168861}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:41,327] Trial 25 finished with value: 0.8025490800698941 and parameters: {'C': 33.67331433791792}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:48,995] Trial 26 finished with value: 0.8025747764415664 and parameters: {'C': 4.774390531075494}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:05:55,608] Trial 27 finished with value: 0.8026261691849111 and parameters: {'C': 24.150352321837374}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:06:03,597] Trial 28 finished with value: 0.8029859183883236 and parameters: {'C': 46.847481495331444}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/tmp/ipython-input-2397602830.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
            "[I 2025-12-11 15:06:09,749] Trial 29 finished with value: 0.8027289546716004 and parameters: {'C': 3.7492756352216845}. Best is trial 22 with value: 0.8030116147599959.\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogReg tuning done (208.2s). Best CV accuracy: 0.8030\n",
            "Best LR params: {'C': 91.33127908521416}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 15:06:23,656] A new study created in memory with name: SVM_opt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR test accuracy: 0.8038026721479958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "[I 2025-12-11 15:08:24,503] Trial 0 finished with value: 0.87195497995683 and parameters: {'C': 40.01101273454871, 'gamma_option': 'auto'}. Best is trial 0 with value: 0.87195497995683.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:10:29,146] Trial 1 finished with value: 0.8267807585568918 and parameters: {'C': 30.0718720401135, 'gamma_option': 'float', 'gamma_float': 0.0022803607384010143}. Best is trial 0 with value: 0.87195497995683.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 15:13:10,128] Trial 2 finished with value: 0.7957138452050571 and parameters: {'C': 0.1312072780558728, 'gamma_option': 'scale'}. Best is trial 0 with value: 0.87195497995683.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 15:15:08,913] Trial 3 finished with value: 0.8441258094357078 and parameters: {'C': 2.7875790498653714, 'gamma_option': 'auto'}. Best is trial 0 with value: 0.87195497995683.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:18:35,558] Trial 4 finished with value: 0.8959810874704491 and parameters: {'C': 2.592361271410355, 'gamma_option': 'float', 'gamma_float': 0.4270083410819702}. Best is trial 4 with value: 0.8959810874704491.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 15:20:37,875] Trial 5 finished with value: 0.8367252543940795 and parameters: {'C': 1.769893545694852, 'gamma_option': 'auto'}. Best is trial 4 with value: 0.8959810874704491.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 15:23:53,074] Trial 6 finished with value: 0.756192825573029 and parameters: {'C': 0.029312604023546084, 'gamma_option': 'auto'}. Best is trial 4 with value: 0.8959810874704491.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 15:25:53,358] Trial 7 finished with value: 0.848083050673245 and parameters: {'C': 3.231288024777066, 'gamma_option': 'scale'}. Best is trial 4 with value: 0.8959810874704491.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:28:39,147] Trial 8 finished with value: 0.9023280912735121 and parameters: {'C': 27.952587462272415, 'gamma_option': 'float', 'gamma_float': 0.2816974823358794}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:32:50,832] Trial 9 finished with value: 0.5882413403227464 and parameters: {'C': 0.01527206500737298, 'gamma_option': 'float', 'gamma_float': 0.0008764201144509334}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:36:58,146] Trial 10 finished with value: 0.8998098468496248 and parameters: {'C': 92.7723083126138, 'gamma_option': 'float', 'gamma_float': 0.4396859107173457}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:41:32,071] Trial 11 finished with value: 0.8989104738410937 and parameters: {'C': 83.55043177702898, 'gamma_option': 'float', 'gamma_float': 0.5030096976861371}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:43:26,674] Trial 12 finished with value: 0.8758351320793505 and parameters: {'C': 10.08954274725954, 'gamma_option': 'float', 'gamma_float': 0.051367691981980566}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:45:23,195] Trial 13 finished with value: 0.8859851988899168 and parameters: {'C': 15.767374802359702, 'gamma_option': 'float', 'gamma_float': 0.06968680951282674}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:51:03,079] Trial 14 finished with value: 0.8421471888169391 and parameters: {'C': 0.46939066112063155, 'gamma_option': 'float', 'gamma_float': 0.9809448905336022}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:53:55,051] Trial 15 finished with value: 0.777957652379484 and parameters: {'C': 9.44053563495094, 'gamma_option': 'float', 'gamma_float': 0.00011227173531161773}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 15:56:00,792] Trial 16 finished with value: 0.8782762873882208 and parameters: {'C': 95.80579402697775, 'gamma_option': 'scale'}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 15:58:10,541] Trial 17 finished with value: 0.8415304758968034 and parameters: {'C': 0.5800752938514049, 'gamma_option': 'float', 'gamma_float': 0.05474732835813938}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:00:28,882] Trial 18 finished with value: 0.9013002364066193 and parameters: {'C': 26.470239152105666, 'gamma_option': 'float', 'gamma_float': 0.15914075376102635}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 16:02:28,877] Trial 19 finished with value: 0.8589783122623086 and parameters: {'C': 8.138378091261064, 'gamma_option': 'scale'}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:04:20,374] Trial 20 finished with value: 0.8646829067735635 and parameters: {'C': 26.322513372314603, 'gamma_option': 'float', 'gamma_float': 0.014065262657172863}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:06:42,732] Trial 21 finished with value: 0.9023023949018399 and parameters: {'C': 40.57405601169151, 'gamma_option': 'float', 'gamma_float': 0.1762473139231129}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:08:50,570] Trial 22 finished with value: 0.9002980779113989 and parameters: {'C': 37.354711994542185, 'gamma_option': 'float', 'gamma_float': 0.11258668744868525}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:11:02,263] Trial 23 finished with value: 0.8895826909240415 and parameters: {'C': 4.659219480281038, 'gamma_option': 'float', 'gamma_float': 0.16237786153178171}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:12:58,305] Trial 24 finished with value: 0.8692054681878919 and parameters: {'C': 20.261328133000696, 'gamma_option': 'float', 'gamma_float': 0.021916379903243098}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:15:15,614] Trial 25 finished with value: 0.896289443930517 and parameters: {'C': 7.022844932073911, 'gamma_option': 'float', 'gamma_float': 0.1925595657636575}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:17:34,341] Trial 26 finished with value: 0.8111573645801213 and parameters: {'C': 1.1867433649993957, 'gamma_option': 'float', 'gamma_float': 0.006774646818931504}. Best is trial 8 with value: 0.9023280912735121.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "/tmp/ipython-input-2397602830.py:77: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform(\"gamma_float\", 1e-4, 1.0)\n",
            "[I 2025-12-11 16:20:04,869] Trial 27 finished with value: 0.9033302497687327 and parameters: {'C': 44.28285265018229, 'gamma_option': 'float', 'gamma_float': 0.23784701986819634}. Best is trial 27 with value: 0.9033302497687327.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 16:22:05,708] Trial 28 finished with value: 0.8746530989824236 and parameters: {'C': 58.35590887631571, 'gamma_option': 'auto'}. Best is trial 27 with value: 0.9033302497687327.\n",
            "/tmp/ipython-input-2397602830.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n",
            "[I 2025-12-11 16:23:59,060] Trial 29 finished with value: 0.8738822078322541 and parameters: {'C': 47.240229614791886, 'gamma_option': 'scale'}. Best is trial 27 with value: 0.9033302497687327.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM tuning done (4655.4s). Best CV accuracy: 0.9033\n",
            "Best SVM params: {'C': 44.28285265018229, 'gamma_option': 'float', 'gamma_float': 0.23784701986819634}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:26:31,423] A new study created in memory with name: MLP_opt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM test accuracy: 0.9171634121274409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:26:45,511] Trial 0 finished with value: 0.8698992702230445 and parameters: {'n_layers': 1, 'n_units_l0': 119, 'alpha': 1.1202532587657478e-06, 'learning_rate_init': 0.04055510972803614, 'batch_size': 1024}. Best is trial 0 with value: 0.8698992702230445.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:31:16,346] Trial 1 finished with value: 0.8894285126940077 and parameters: {'n_layers': 2, 'n_units_l0': 115, 'n_units_l1': 418, 'alpha': 0.003710862634779174, 'learning_rate_init': 0.00026359573864717233, 'batch_size': 256}. Best is trial 1 with value: 0.8894285126940077.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:33:43,665] Trial 2 finished with value: 0.7914739438791242 and parameters: {'n_layers': 3, 'n_units_l0': 449, 'n_units_l1': 184, 'n_units_l2': 304, 'alpha': 0.00525310456221383, 'learning_rate_init': 0.044873566123892344, 'batch_size': 256}. Best is trial 1 with value: 0.8894285126940077.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:39:52,319] Trial 3 finished with value: 0.8837239181827526 and parameters: {'n_layers': 2, 'n_units_l0': 505, 'n_units_l1': 451, 'alpha': 0.00022271012903859173, 'learning_rate_init': 0.03399919588044087, 'batch_size': 1024}. Best is trial 1 with value: 0.8894285126940077.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:44:07,710] Trial 4 finished with value: 0.8976513516291499 and parameters: {'n_layers': 2, 'n_units_l0': 374, 'n_units_l1': 457, 'alpha': 0.00013695600565345544, 'learning_rate_init': 0.007100266432493465, 'batch_size': 256}. Best is trial 4 with value: 0.8976513516291499.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:46:44,799] Trial 5 finished with value: 0.9033302497687327 and parameters: {'n_layers': 3, 'n_units_l0': 68, 'n_units_l1': 208, 'n_units_l2': 510, 'alpha': 2.0769110155605416e-06, 'learning_rate_init': 0.004556272795030406, 'batch_size': 1024}. Best is trial 5 with value: 0.9033302497687327.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:47:50,331] Trial 6 finished with value: 0.7014595539109877 and parameters: {'n_layers': 3, 'n_units_l0': 426, 'n_units_l1': 86, 'n_units_l2': 192, 'alpha': 0.00012503155766015569, 'learning_rate_init': 0.05821177047247096, 'batch_size': 256}. Best is trial 5 with value: 0.9033302497687327.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:54:43,733] Trial 7 finished with value: 0.9093432007400555 and parameters: {'n_layers': 3, 'n_units_l0': 331, 'n_units_l1': 338, 'n_units_l2': 498, 'alpha': 0.003105508623081291, 'learning_rate_init': 0.0031035965668983322, 'batch_size': 256}. Best is trial 7 with value: 0.9093432007400555.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 16:55:39,763] Trial 8 finished with value: 0.8833384726076678 and parameters: {'n_layers': 2, 'n_units_l0': 92, 'n_units_l1': 312, 'alpha': 2.7195880161704712e-05, 'learning_rate_init': 0.0254363613699888, 'batch_size': 512}. Best is trial 7 with value: 0.9093432007400555.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:02:59,396] Trial 9 finished with value: 0.8754239901325933 and parameters: {'n_layers': 2, 'n_units_l0': 425, 'n_units_l1': 294, 'alpha': 5.3107996588349135e-05, 'learning_rate_init': 0.0001676059790458716, 'batch_size': 1024}. Best is trial 7 with value: 0.9093432007400555.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:04:06,096] Trial 10 finished with value: 0.8739079042039264 and parameters: {'n_layers': 1, 'n_units_l0': 246, 'alpha': 0.001096775062536906, 'learning_rate_init': 0.0009562748522951731, 'batch_size': 512}. Best is trial 7 with value: 0.9093432007400555.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:08:32,850] Trial 11 finished with value: 0.9105766265803269 and parameters: {'n_layers': 3, 'n_units_l0': 256, 'n_units_l1': 194, 'n_units_l2': 498, 'alpha': 1.2621465296175297e-06, 'learning_rate_init': 0.00375059088803119, 'batch_size': 1024}. Best is trial 11 with value: 0.9105766265803269.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:14:56,062] Trial 12 finished with value: 0.8983194572926303 and parameters: {'n_layers': 3, 'n_units_l0': 267, 'n_units_l1': 358, 'n_units_l2': 495, 'alpha': 1.0776265632484275e-05, 'learning_rate_init': 0.0013515750692427873, 'batch_size': 1024}. Best is trial 11 with value: 0.9105766265803269.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:19:08,485] Trial 13 finished with value: 0.8980111008325625 and parameters: {'n_layers': 3, 'n_units_l0': 201, 'n_units_l1': 205, 'n_units_l2': 406, 'alpha': 0.0007845546522161472, 'learning_rate_init': 0.010208283878868043, 'batch_size': 256}. Best is trial 11 with value: 0.9105766265803269.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:23:52,589] Trial 14 finished with value: 0.9165124884366328 and parameters: {'n_layers': 3, 'n_units_l0': 343, 'n_units_l1': 115, 'n_units_l2': 379, 'alpha': 5.699775016740227e-06, 'learning_rate_init': 0.0014946077819960092, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:25:14,964] Trial 15 finished with value: 0.883441258094357 and parameters: {'n_layers': 3, 'n_units_l0': 187, 'n_units_l1': 64, 'n_units_l2': 344, 'alpha': 5.670496923813478e-06, 'learning_rate_init': 0.0006976699925678744, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:29:09,565] Trial 16 finished with value: 0.912041319765649 and parameters: {'n_layers': 3, 'n_units_l0': 333, 'n_units_l1': 133, 'n_units_l2': 396, 'alpha': 4.573293504376291e-06, 'learning_rate_init': 0.0020434257627354206, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:32:05,650] Trial 17 finished with value: 0.8896083872957138 and parameters: {'n_layers': 2, 'n_units_l0': 336, 'n_units_l1': 126, 'alpha': 6.2086731548326395e-06, 'learning_rate_init': 0.00041351132946816155, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:33:03,388] Trial 18 finished with value: 0.8705416795148525 and parameters: {'n_layers': 1, 'n_units_l0': 327, 'alpha': 1.566049251199542e-05, 'learning_rate_init': 0.001665903760550596, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:41:34,217] Trial 19 finished with value: 0.8852913968547641 and parameters: {'n_layers': 3, 'n_units_l0': 382, 'n_units_l1': 134, 'n_units_l2': 383, 'alpha': 3.423511802796149e-06, 'learning_rate_init': 0.00010097894713339144, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:43:35,177] Trial 20 finished with value: 0.8940795559666975 and parameters: {'n_layers': 2, 'n_units_l0': 303, 'n_units_l1': 260, 'alpha': 3.7736181937532564e-05, 'learning_rate_init': 0.013434115197535724, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:46:04,774] Trial 21 finished with value: 0.9055658341042245 and parameters: {'n_layers': 3, 'n_units_l0': 229, 'n_units_l1': 140, 'n_units_l2': 421, 'alpha': 1.9699199029809747e-06, 'learning_rate_init': 0.002564302424292696, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:51:02,640] Trial 22 finished with value: 0.9070819200328915 and parameters: {'n_layers': 3, 'n_units_l0': 287, 'n_units_l1': 245, 'n_units_l2': 432, 'alpha': 1.0417337287256102e-06, 'learning_rate_init': 0.005350996197121571, 'batch_size': 1024}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:55:00,113] Trial 23 finished with value: 0.9007349162298284 and parameters: {'n_layers': 3, 'n_units_l0': 375, 'n_units_l1': 154, 'n_units_l2': 228, 'alpha': 5.51998265020705e-06, 'learning_rate_init': 0.0005978247493152253, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 17:56:25,116] Trial 24 finished with value: 0.9056172268475692 and parameters: {'n_layers': 3, 'n_units_l0': 166, 'n_units_l1': 90, 'n_units_l2': 76, 'alpha': 1.1304904013304697e-05, 'learning_rate_init': 0.0017049166154137038, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 18:01:01,908] Trial 25 finished with value: 0.9129663891458527 and parameters: {'n_layers': 3, 'n_units_l0': 285, 'n_units_l1': 179, 'n_units_l2': 340, 'alpha': 2.4767656576015247e-06, 'learning_rate_init': 0.002565489778273421, 'batch_size': 1024}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 18:04:00,570] Trial 26 finished with value: 0.9108849830403947 and parameters: {'n_layers': 3, 'n_units_l0': 296, 'n_units_l1': 110, 'n_units_l2': 339, 'alpha': 2.939681953997168e-06, 'learning_rate_init': 0.002076046217961056, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 18:06:55,182] Trial 27 finished with value: 0.8937711995066296 and parameters: {'n_layers': 2, 'n_units_l0': 352, 'n_units_l1': 171, 'alpha': 2.1050758403673985e-05, 'learning_rate_init': 0.0010000828686834728, 'batch_size': 1024}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 18:10:21,056] Trial 28 finished with value: 0.8868845718984479 and parameters: {'n_layers': 3, 'n_units_l0': 410, 'n_units_l1': 240, 'n_units_l2': 241, 'alpha': 5.623722955439104e-05, 'learning_rate_init': 0.01655020584896746, 'batch_size': 512}. Best is trial 14 with value: 0.9165124884366328.\n",
            "/tmp/ipython-input-2397602830.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  alpha = trial.suggest_loguniform(\"alpha\", 1e-6, 1e-2)\n",
            "/tmp/ipython-input-2397602830.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-1)\n",
            "[I 2025-12-11 18:11:32,505] Trial 29 finished with value: 0.8896083872957138 and parameters: {'n_layers': 1, 'n_units_l0': 475, 'alpha': 8.25541498563264e-06, 'learning_rate_init': 0.007510471163850183, 'batch_size': 1024}. Best is trial 14 with value: 0.9165124884366328.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP tuning done (6301.1s). Best CV accuracy: 0.9165\n",
            "Best MLP params: {'n_layers': 3, 'n_units_l0': 343, 'n_units_l1': 115, 'n_units_l2': 379, 'alpha': 5.699775016740227e-06, 'learning_rate_init': 0.0014946077819960092, 'batch_size': 512}\n",
            "Iteration 1, loss = 0.66309564\n",
            "Validation score: 0.818859\n",
            "Iteration 2, loss = 0.43781226\n",
            "Validation score: 0.839928\n",
            "Iteration 3, loss = 0.40008267\n",
            "Validation score: 0.849178\n",
            "Iteration 4, loss = 0.37164217\n",
            "Validation score: 0.843011\n",
            "Iteration 5, loss = 0.34935581\n",
            "Validation score: 0.860226\n",
            "Iteration 6, loss = 0.33464344\n",
            "Validation score: 0.862025\n",
            "Iteration 7, loss = 0.31630885\n",
            "Validation score: 0.874872\n",
            "Iteration 8, loss = 0.30383188\n",
            "Validation score: 0.881038\n",
            "Iteration 9, loss = 0.29318279\n",
            "Validation score: 0.874101\n",
            "Iteration 10, loss = 0.28201061\n",
            "Validation score: 0.884892\n",
            "Iteration 11, loss = 0.27276467\n",
            "Validation score: 0.889774\n",
            "Iteration 12, loss = 0.26058450\n",
            "Validation score: 0.893371\n",
            "Iteration 13, loss = 0.25043073\n",
            "Validation score: 0.883350\n",
            "Iteration 14, loss = 0.24593564\n",
            "Validation score: 0.890545\n",
            "Iteration 15, loss = 0.23813442\n",
            "Validation score: 0.896197\n",
            "Iteration 16, loss = 0.23172497\n",
            "Validation score: 0.898253\n",
            "Iteration 17, loss = 0.22660919\n",
            "Validation score: 0.901336\n",
            "Iteration 18, loss = 0.21768642\n",
            "Validation score: 0.902107\n",
            "Iteration 19, loss = 0.21740735\n",
            "Validation score: 0.901593\n",
            "Iteration 20, loss = 0.21016349\n",
            "Validation score: 0.897739\n",
            "Iteration 21, loss = 0.19869023\n",
            "Validation score: 0.904676\n",
            "Iteration 22, loss = 0.19820823\n",
            "Validation score: 0.905961\n",
            "Iteration 23, loss = 0.19896231\n",
            "Validation score: 0.906989\n",
            "Iteration 24, loss = 0.19640275\n",
            "Validation score: 0.904162\n",
            "Iteration 25, loss = 0.18583156\n",
            "Validation score: 0.911100\n",
            "Iteration 26, loss = 0.18282497\n",
            "Validation score: 0.907760\n",
            "Iteration 27, loss = 0.17952939\n",
            "Validation score: 0.915982\n",
            "Iteration 28, loss = 0.17788748\n",
            "Validation score: 0.905704\n",
            "Iteration 29, loss = 0.16982816\n",
            "Validation score: 0.912384\n",
            "Iteration 30, loss = 0.16628842\n",
            "Validation score: 0.915725\n",
            "Iteration 31, loss = 0.16013871\n",
            "Validation score: 0.918037\n",
            "Iteration 32, loss = 0.16517243\n",
            "Validation score: 0.913926\n",
            "Iteration 33, loss = 0.15785811\n",
            "Validation score: 0.909301\n",
            "Iteration 34, loss = 0.15857445\n",
            "Validation score: 0.919836\n",
            "Iteration 35, loss = 0.14758150\n",
            "Validation score: 0.918808\n",
            "Iteration 36, loss = 0.15029912\n",
            "Validation score: 0.913926\n",
            "Iteration 37, loss = 0.14974198\n",
            "Validation score: 0.922148\n",
            "Iteration 38, loss = 0.14150418\n",
            "Validation score: 0.920606\n",
            "Iteration 39, loss = 0.14144096\n",
            "Validation score: 0.920092\n",
            "Iteration 40, loss = 0.14075779\n",
            "Validation score: 0.919322\n",
            "Iteration 41, loss = 0.13708589\n",
            "Validation score: 0.922919\n",
            "Iteration 42, loss = 0.13758097\n",
            "Validation score: 0.912898\n",
            "Iteration 43, loss = 0.13944038\n",
            "Validation score: 0.923947\n",
            "Iteration 44, loss = 0.13066257\n",
            "Validation score: 0.923947\n",
            "Iteration 45, loss = 0.12630530\n",
            "Validation score: 0.914954\n",
            "Iteration 46, loss = 0.12593564\n",
            "Validation score: 0.920863\n",
            "Iteration 47, loss = 0.12302871\n",
            "Validation score: 0.926516\n",
            "Iteration 48, loss = 0.12374990\n",
            "Validation score: 0.921634\n",
            "Iteration 49, loss = 0.12016584\n",
            "Validation score: 0.919322\n",
            "Iteration 50, loss = 0.12447858\n",
            "Validation score: 0.924203\n",
            "Iteration 51, loss = 0.11521983\n",
            "Validation score: 0.925745\n",
            "Iteration 52, loss = 0.11763979\n",
            "Validation score: 0.925745\n",
            "Iteration 53, loss = 0.11058869\n",
            "Validation score: 0.923433\n",
            "Iteration 54, loss = 0.12251398\n",
            "Validation score: 0.925231\n",
            "Iteration 55, loss = 0.11260381\n",
            "Validation score: 0.927287\n",
            "Iteration 56, loss = 0.11049011\n",
            "Validation score: 0.928314\n",
            "Iteration 57, loss = 0.10372513\n",
            "Validation score: 0.930627\n",
            "Iteration 58, loss = 0.09964691\n",
            "Validation score: 0.926516\n",
            "Iteration 59, loss = 0.10299159\n",
            "Validation score: 0.924460\n",
            "Iteration 60, loss = 0.10243414\n",
            "Validation score: 0.930370\n",
            "Iteration 61, loss = 0.09930248\n",
            "Validation score: 0.927030\n",
            "Iteration 62, loss = 0.09458496\n",
            "Validation score: 0.927544\n",
            "Iteration 63, loss = 0.10054968\n",
            "Validation score: 0.929085\n",
            "Iteration 64, loss = 0.09713857\n",
            "Validation score: 0.931912\n",
            "Iteration 65, loss = 0.09570249\n",
            "Validation score: 0.921120\n",
            "Iteration 66, loss = 0.09353000\n",
            "Validation score: 0.929856\n",
            "Iteration 67, loss = 0.09349157\n",
            "Validation score: 0.925488\n",
            "Iteration 68, loss = 0.09458254\n",
            "Validation score: 0.928058\n",
            "Iteration 69, loss = 0.08836451\n",
            "Validation score: 0.926002\n",
            "Iteration 70, loss = 0.09509161\n",
            "Validation score: 0.921634\n",
            "Iteration 71, loss = 0.08469309\n",
            "Validation score: 0.928828\n",
            "Iteration 72, loss = 0.08638638\n",
            "Validation score: 0.933196\n",
            "Iteration 73, loss = 0.08919346\n",
            "Validation score: 0.930113\n",
            "Iteration 74, loss = 0.08107530\n",
            "Validation score: 0.925488\n",
            "Iteration 75, loss = 0.08621905\n",
            "Validation score: 0.930370\n",
            "Iteration 76, loss = 0.08192367\n",
            "Validation score: 0.932939\n",
            "Iteration 77, loss = 0.08653263\n",
            "Validation score: 0.924974\n",
            "Iteration 78, loss = 0.07976288\n",
            "Validation score: 0.931141\n",
            "Iteration 79, loss = 0.08126298\n",
            "Validation score: 0.928314\n",
            "Iteration 80, loss = 0.08676894\n",
            "Validation score: 0.925231\n",
            "Iteration 81, loss = 0.08033815\n",
            "Validation score: 0.929856\n",
            "Iteration 82, loss = 0.08020897\n",
            "Validation score: 0.931398\n",
            "Iteration 83, loss = 0.07347491\n",
            "Validation score: 0.930113\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "MLP test accuracy: 0.9221993833504625\n",
            "\n",
            "=== Optuna summary ===\n",
            "                model   best_cv  test_acc  \\\n",
            "0  LogisticRegression  0.803012  0.803803   \n",
            "1            SVM(RBF)  0.903330  0.917163   \n",
            "2                 MLP  0.916512  0.922199   \n",
            "\n",
            "                                         best_params  \n",
            "0                           {'C': 91.33127908521416}  \n",
            "1  {'C': 44.28285265018229, 'gamma_option': 'floa...  \n",
            "2  {'n_layers': 3, 'n_units_l0': 343, 'n_units_l1...  \n",
            "Saved all Optuna studies.\n"
          ]
        }
      ]
    }
  ]
}